{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv')\ntrain_df.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:11:34.53433Z","iopub.execute_input":"2025-11-14T16:11:34.535137Z","iopub.status.idle":"2025-11-14T16:11:34.835505Z","shell.execute_reply.started":"2025-11-14T16:11:34.535111Z","shell.execute_reply":"2025-11-14T16:11:34.834668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\nlocation_cols = [col for col in train_df.columns if col not in ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Aneurysm Present']]\nlocation_counts = train_df[location_cols].sum().sort_values(ascending=False)\n\nfig = px.bar(\n    location_counts,\n    orientation='v',\n    title=' Aneurysm Count by Location',\n    labels={'value': 'Count', 'index': 'Location'},\n    color=location_counts.values,\n    \n)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:14:37.636476Z","iopub.execute_input":"2025-11-14T16:14:37.636945Z","iopub.status.idle":"2025-11-14T16:14:37.683333Z","shell.execute_reply.started":"2025-11-14T16:14:37.63692Z","shell.execute_reply":"2025-11-14T16:14:37.68271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(10,6))\nsns.histplot(\n    data=train_df,\n    x='PatientAge',\n    hue='Aneurysm Present',\n    bins=30,\n    kde=True,\n    palette={0: '#00BFC4', 1: '#C77CFF'}\n)\nplt.title(\"Age Distribution by Aneurysm Presence\", fontsize=14)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Frequency\")\nplt.grid(alpha=0.2)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:15:36.005969Z","iopub.execute_input":"2025-11-14T16:15:36.006665Z","iopub.status.idle":"2025-11-14T16:15:36.346948Z","shell.execute_reply.started":"2025-11-14T16:15:36.006639Z","shell.execute_reply":"2025-11-14T16:15:36.346283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.histogram(\n    train_df,\n    x='Aneurysm Present',\n    title='âš–ï¸ Class Imbalance: Any Aneurysm Present',\n    color='Aneurysm Present',\n    text_auto=True,\n    color_discrete_map={0: '#00BFC4', 1: '#C77CFF'},\n    template='plotly_dark'\n)\nfig.update_xaxes(type='category', tickvals=[0, 1], ticktext=[\"No Aneurysm\", \"Aneurysm\"])\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:16:34.180916Z","iopub.execute_input":"2025-11-14T16:16:34.181233Z","iopub.status.idle":"2025-11-14T16:16:34.278448Z","shell.execute_reply.started":"2025-11-14T16:16:34.181213Z","shell.execute_reply":"2025-11-14T16:16:34.277833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simple % table (can be styled in notebook output)\ngender_ct = pd.crosstab(train_df['PatientSex'], train_df['Aneurysm Present'], normalize='index') * 100\ngender_ct = gender_ct.rename(columns={0: 'No Aneurysm (%)', 1: 'Aneurysm (%)'})\ngender_ct.style.background_gradient(cmap='crest').format(\"{:.1f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:17:17.558325Z","iopub.execute_input":"2025-11-14T16:17:17.558854Z","iopub.status.idle":"2025-11-14T16:17:17.654169Z","shell.execute_reply.started":"2025-11-14T16:17:17.558834Z","shell.execute_reply":"2025-11-14T16:17:17.653576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport ast\n\nlocalizers_df = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv')\n\n# Convert coordinate strings to dicts\nlocalizers_df['coords'] = localizers_df['coordinates'].apply(ast.literal_eval)\nlocalizers_df['x'] = localizers_df['coords'].apply(lambda d: d['x'])\nlocalizers_df['y'] = localizers_df['coords'].apply(lambda d: d['y'])\n\nlocalizers_df.drop(columns=['coordinates', 'coords'], inplace=True)\nlocalizers_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:18:37.347763Z","iopub.execute_input":"2025-11-14T16:18:37.348616Z","iopub.status.idle":"2025-11-14T16:18:37.409982Z","shell.execute_reply.started":"2025-11-14T16:18:37.348591Z","shell.execute_reply":"2025-11-14T16:18:37.409396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.density_heatmap(\n    localizers_df,\n    x='x',\n    y='y',\n    nbinsx=50,\n    nbinsy=50,\n    title='ðŸ§  Heatmap of Aneurysm Locations in 2D Image Space',\n    color_continuous_scale='Turbo',\n    template='plotly_dark',\n)\nfig.update_yaxes(autorange=\"reversed\")\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:19:14.237784Z","iopub.execute_input":"2025-11-14T16:19:14.238269Z","iopub.status.idle":"2025-11-14T16:19:14.277393Z","shell.execute_reply.started":"2025-11-14T16:19:14.238245Z","shell.execute_reply":"2025-11-14T16:19:14.276761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter(\n    localizers_df,\n    x='x',\n    y='y',\n    color='location',\n    title='ðŸ§  2D Scatter of Aneurysm Coordinates by Location',\n    template='plotly_dark',\n    color_discrete_sequence=px.colors.qualitative.Dark24\n)\nfig.update_yaxes(autorange=\"reversed\")\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:19:33.518548Z","iopub.execute_input":"2025-11-14T16:19:33.518839Z","iopub.status.idle":"2025-11-14T16:19:33.589132Z","shell.execute_reply.started":"2025-11-14T16:19:33.51882Z","shell.execute_reply":"2025-11-14T16:19:33.588403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = train_df\n# Identify location columns correctly\nlocation_cols = df.columns[4:-1]  # skip UID, Age, Sex, Modality, and skip final label\nlocation_df = df[location_cols].astype(int)  # just in case they're still object type\n\n# Co-occurrence matrix\nco_matrix = location_df.T.dot(location_df)\n\n# Plot heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(co_matrix, cmap=\"magma\", annot=True, fmt=\".0f\", linewidths=0.5)\nplt.title(\"ðŸ§  Aneurysm Co-occurrence Matrix\", fontsize=16, color='white')\nplt.xticks(rotation=45, ha='right', fontsize=9)\nplt.yticks(rotation=0, fontsize=9)\nplt.gca().set_facecolor('black')\nplt.gcf().set_facecolor('#111111')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:21:05.489195Z","iopub.execute_input":"2025-11-14T16:21:05.489819Z","iopub.status.idle":"2025-11-14T16:21:06.080563Z","shell.execute_reply.started":"2025-11-14T16:21:05.489794Z","shell.execute_reply":"2025-11-14T16:21:06.079748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1. Location Count Distribution (number of 1s per row)\nlocation_counts = location_df.sum(axis=1)\n\nplt.figure(figsize=(8, 5))\nsns.histplot(location_counts, bins=range(1, location_counts.max()+2), kde=False, color=\"teal\")\nplt.title(\"Distribution of Aneurysm Locations per Patient\")\nplt.xlabel(\"Number of Locations with Aneurysm\")\nplt.ylabel(\"Number of Patients\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:22:03.219842Z","iopub.execute_input":"2025-11-14T16:22:03.22059Z","iopub.status.idle":"2025-11-14T16:22:03.413981Z","shell.execute_reply.started":"2025-11-14T16:22:03.220564Z","shell.execute_reply":"2025-11-14T16:22:03.413404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming 'df' is already loaded and preprocessed (i.e., binary columns are int)\n\n# Filter only rows where aneurysm is present\ndf_pos = df[df[\"Aneurysm Present\"] == 1]\n\n# List of all aneurysm location columns\nlocation_cols = df_pos.columns[4:-1]  # From 'Left Infraclinoid...' to 'Other Posterior Circulation'\n\n# Group by PatientSex and sum each location\nsex_location = df_pos.groupby(\"PatientSex\")[location_cols].sum().T\n\n# Reset index for plotting\nsex_location = sex_location.reset_index().melt(id_vars=\"index\", var_name=\"Sex\", value_name=\"Count\")\nsex_location = sex_location.rename(columns={\"index\": \"Location\"})\n\n# Plot\nplt.figure(figsize=(16, 6))\nsns.barplot(data=sex_location, x=\"Location\", y=\"Count\", hue=\"Sex\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"ðŸ§¬ Aneurysm Location Frequency by Sex\")\nplt.ylabel(\"Aneurysm Count\")\nplt.xlabel(\"Location\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:23:04.275654Z","iopub.execute_input":"2025-11-14T16:23:04.27641Z","iopub.status.idle":"2025-11-14T16:23:04.612153Z","shell.execute_reply.started":"2025-11-14T16:23:04.276377Z","shell.execute_reply":"2025-11-14T16:23:04.611535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter rows with aneurysm present\ndf_pos = df[df[\"Aneurysm Present\"] == 1].copy()\n\n# Initialize a dictionary to store counts\nmodality_counts = {}\n\nfor loc in location_cols:\n    subset = df_pos[df_pos[loc] == 1]\n    modality_distribution = subset[\"Modality\"].value_counts()\n    modality_counts[loc] = modality_distribution\n\n# Convert to DataFrame and fill missing values with 0\nmodality_df = pd.DataFrame(modality_counts).T.fillna(0).astype(int)\nmodality_df = modality_df[[\"CTA\", \"MRA\"]] if \"CTA\" in modality_df.columns and \"MRA\" in modality_df.columns else modality_df\n\n# Plot heatmap\nplt.figure(figsize=(12, 6))\nsns.heatmap(modality_df.T, annot=True, cmap=\"crest\", fmt=\"d\")\nplt.title(\"ðŸ§  Modality Preference per Aneurysm Location\")\nplt.xlabel(\"Location\")\nplt.ylabel(\"Modality\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:24:21.601963Z","iopub.execute_input":"2025-11-14T16:24:21.602527Z","iopub.status.idle":"2025-11-14T16:24:22.086831Z","shell.execute_reply.started":"2025-11-14T16:24:21.6025Z","shell.execute_reply":"2025-11-14T16:24:22.086097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"modality_df_melted = modality_df.reset_index().melt(id_vars=\"index\", value_name=\"Count\", var_name=\"Modality\")\nmodality_df_melted.rename(columns={\"index\": \"Location\"}, inplace=True)\n\nplt.figure(figsize=(14, 6))\nsns.barplot(data=modality_df_melted, x=\"Location\", y=\"Count\", hue=\"Modality\", palette=\"crest\")\nplt.title(\"ðŸ§  Modality Usage per Aneurysm Location\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.xlabel(\"Location\")\nplt.ylabel(\"Patient Count\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:24:34.016893Z","iopub.execute_input":"2025-11-14T16:24:34.017604Z","iopub.status.idle":"2025-11-14T16:24:34.335534Z","shell.execute_reply.started":"2025-11-14T16:24:34.017581Z","shell.execute_reply":"2025-11-14T16:24:34.33478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\n\ntrain_localizations = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv\")\n# Parse coordinates\ntrain_localizations[\"coord_dict\"] = train_localizations[\"coordinates\"].apply(ast.literal_eval)\ntrain_localizations[\"x\"] = train_localizations[\"coord_dict\"].apply(lambda d: d[\"x\"])\ntrain_localizations[\"y\"] = train_localizations[\"coord_dict\"].apply(lambda d: d[\"y\"])\n\n# Top 4-5 most frequent locations\ntop_locations = train_localizations[\"location\"].value_counts().head(5).index\n\n# Plot heatmap per location\nfor loc in top_locations:\n    subset = train_localizations[train_localizations[\"location\"] == loc]\n    plt.figure(figsize=(6, 5))\n    sns.kdeplot(data=subset, x=\"x\", y=\"y\", fill=True, cmap=\"crest\")\n    plt.title(f\"ðŸ§­ Spatial Heatmap for {loc}\")\n    plt.xlabel(\"X Coordinate\")\n    plt.ylabel(\"Y Coordinate\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:25:34.690841Z","iopub.execute_input":"2025-11-14T16:25:34.691123Z","iopub.status.idle":"2025-11-14T16:25:36.724693Z","shell.execute_reply.started":"2025-11-14T16:25:34.691103Z","shell.execute_reply":"2025-11-14T16:25:36.723955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv\")\n# Frequency from train.csv\nlabel_freq = train[location_cols].sum().sort_values(ascending=False).rename(\"train.csv\")\n\n# Frequency from localizations.csv\nlocalizer_freq = train_localizations[\"location\"].value_counts().rename(\"train_localizations.csv\")\n\n# Combine\nfreq_comparison = pd.concat([label_freq, localizer_freq], axis=1).fillna(0).astype(int)\n\n# Bar plot\nfreq_comparison.plot(kind=\"bar\", figsize=(14, 6), color=['#00BFC4',  '#C77CFF'])\nplt.title(\"ðŸ”„ Frequency Comparison of Aneurysm Locations\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:25:42.279896Z","iopub.execute_input":"2025-11-14T16:25:42.28019Z","iopub.status.idle":"2025-11-14T16:25:42.623554Z","shell.execute_reply.started":"2025-11-14T16:25:42.280167Z","shell.execute_reply":"2025-11-14T16:25:42.62286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nseries_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/series'\nseries_folders = [f for f in os.listdir(series_dir) if os.path.isdir(os.path.join(series_dir, f))]\n\nseries_counts = []\nfor folder in series_folders:\n    dcm_files = os.listdir(os.path.join(series_dir, folder))\n    series_counts.append({'SeriesInstanceUID': folder, 'NumSlices': len(dcm_files)})\n\ndf_series = pd.DataFrame(series_counts)\ndf_series.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:25:56.372598Z","iopub.execute_input":"2025-11-14T16:25:56.373336Z","iopub.status.idle":"2025-11-14T16:32:02.433972Z","shell.execute_reply.started":"2025-11-14T16:25:56.373314Z","shell.execute_reply":"2025-11-14T16:32:02.433173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\n\nsample_path = os.path.join(series_dir, series_folders[0])\nsample_file = os.listdir(sample_path)[0]\ndcm = pydicom.dcmread(os.path.join(sample_path, sample_file))\n\nprint(f\"Orientation: {dcm.ImageOrientationPatient}\")\nprint(f\"Voxel spacing: {dcm.PixelSpacing}\")\nprint(f\"Slice Thickness: {dcm.SliceThickness}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:32:15.202881Z","iopub.execute_input":"2025-11-14T16:32:15.203526Z","iopub.status.idle":"2025-11-14T16:32:15.697172Z","shell.execute_reply.started":"2025-11-14T16:32:15.203498Z","shell.execute_reply":"2025-11-14T16:32:15.696406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.widgets as widgets\nimport numpy as np\n\ndef load_series(series_path):\n    files = sorted(os.listdir(series_path), key=lambda x: pydicom.dcmread(os.path.join(series_path, x)).InstanceNumber)\n    images = [pydicom.dcmread(os.path.join(series_path, f)).pixel_array for f in files]\n    return np.stack(images)\n\nvolume = load_series(os.path.join(series_dir, series_folders[0]))\n\n# Scrollable plot\nfrom ipywidgets import interact\n@interact(slice=(0, volume.shape[0]-1))\ndef show_slice(slice=0):\n    plt.imshow(volume[slice], cmap='gray')\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:32:20.705712Z","iopub.execute_input":"2025-11-14T16:32:20.706301Z","iopub.status.idle":"2025-11-14T16:32:23.960058Z","shell.execute_reply.started":"2025-11-14T16:32:20.706279Z","shell.execute_reply":"2025-11-14T16:32:23.959302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pydicom\n\n# Count slices and shape per series\ndicom_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/series'\nseries_stats = []\n\nfor series_id in os.listdir(dicom_dir)[:50]:  # limit for speed\n    series_path = os.path.join(dicom_dir, series_id)\n    files = os.listdir(series_path)\n    num_slices = len(files)\n    sample_dcm = pydicom.dcmread(os.path.join(series_path, files[0]))\n    shape = (sample_dcm.Rows, sample_dcm.Columns)\n    series_stats.append({\"SeriesInstanceUID\": series_id, \"Slices\": num_slices, \"Shape\": shape})\n\npd.DataFrame(series_stats).value_counts(\"Shape\").plot(kind=\"barh\", title=\"ðŸ–¼ Common Image Resolutions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:32:50.300331Z","iopub.execute_input":"2025-11-14T16:32:50.300939Z","iopub.status.idle":"2025-11-14T16:32:52.509123Z","shell.execute_reply.started":"2025-11-14T16:32:50.300913Z","shell.execute_reply":"2025-11-14T16:32:52.50841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"voxel_data = []\n\nfor series_id in os.listdir(dicom_dir)[:50]:\n    slices = []\n    for f in sorted(os.listdir(os.path.join(dicom_dir, series_id))):\n        path = os.path.join(dicom_dir, series_id, f)\n        dcm = pydicom.dcmread(path)\n        slices.append(dcm)\n\n    try:\n        spacing = slices[0].PixelSpacing\n        thickness = float(slices[0].SliceThickness)\n        voxel_data.append({\n            \"SeriesInstanceUID\": series_id,\n            \"PixelSpacingX\": spacing[0],\n            \"PixelSpacingY\": spacing[1],\n            \"SliceThickness\": thickness,\n            \"NumSlices\": len(slices)\n        })\n    except:\n        continue\n\nvoxel_df = pd.DataFrame(voxel_data)\nsns.histplot(voxel_df[\"SliceThickness\"], bins=20)\nplt.title(\"ðŸ“ Slice Thickness Distribution\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:32:54.925679Z","iopub.execute_input":"2025-11-14T16:32:54.925954Z","iopub.status.idle":"2025-11-14T16:35:00.319296Z","shell.execute_reply.started":"2025-11-14T16:32:54.925933Z","shell.execute_reply":"2025-11-14T16:35:00.318682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport gc\nfrom collections import defaultdict\nfrom typing import Tuple, List\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport pydicom\nfrom scipy import ndimage\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\n\nimport kaggle_evaluation.rsna_inference_server\n\n# Competition constants\nID_COL = 'SeriesInstanceUID'\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\nDICOM_TAG_ALLOWLIST = [\n    'BitsAllocated', 'BitsStored', 'Columns', 'FrameOfReferenceUID', 'HighBit',\n    'ImageOrientationPatient', 'ImagePositionPatient', 'InstanceNumber', 'Modality',\n    'PatientID', 'PhotometricInterpretation', 'PixelRepresentation', 'PixelSpacing',\n    'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope', 'RescaleType', 'Rows',\n    'SOPClassUID', 'SOPInstanceUID', 'SamplesPerPixel', 'SliceThickness',\n    'SpacingBetweenSlices', 'StudyInstanceUID', 'TransferSyntaxUID',\n]\n\n# Model configuration\nTARGET_SIZE = (64, 64, 64)  # Reduced size for memory efficiency\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass DICOMProcessor:\n    \"\"\"Process DICOM series into normalized 3D volumes\"\"\"\n    \n    def __init__(self, target_size: Tuple[int, int, int] = TARGET_SIZE):\n        self.target_size = target_size\n        self.scaler = StandardScaler()\n    \n    def load_dicom_series(self, series_path: str) -> np.ndarray:\n        \"\"\"Load and process a DICOM series into a 3D volume\"\"\"\n        try:\n            # Get all DICOM files\n            dicom_files = []\n            for root, _, files in os.walk(series_path):\n                for file in files:\n                    if file.endswith('.dcm'):\n                        dicom_files.append(os.path.join(root, file))\n            \n            if not dicom_files:\n                raise ValueError(f\"No DICOM files found in {series_path}\")\n            \n            # Load DICOMs and sort by instance number\n            dicoms = []\n            for filepath in dicom_files:\n                try:\n                    ds = pydicom.dcmread(filepath, force=True)\n                    if hasattr(ds, 'PixelData'):\n                        dicoms.append((ds, filepath))\n                except Exception as e:\n                    print(f\"Error reading {filepath}: {e}\")\n                    continue\n            \n            if not dicoms:\n                raise ValueError(f\"No valid DICOM files with pixel data in {series_path}\")\n            \n            # Sort by instance number\n            dicoms.sort(key=lambda x: getattr(x[0], 'InstanceNumber', 0))\n            \n            # Extract volume\n            volume_slices = []\n            for ds, _ in dicoms:\n                try:\n                    # Get pixel array\n                    pixel_array = ds.pixel_array.astype(np.float32)\n                    \n                    # Apply rescale if available\n                    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n                        slope = float(ds.RescaleSlope)\n                        intercept = float(ds.RescaleIntercept)\n                        pixel_array = pixel_array * slope + intercept\n                    \n                    volume_slices.append(pixel_array)\n                except Exception as e:\n                    print(f\"Error processing slice: {e}\")\n                    continue\n            \n            if not volume_slices:\n                raise ValueError(\"No valid slices extracted\")\n            \n            # Stack into 3D volume\n            volume = np.stack(volume_slices, axis=0)  # Shape: (depth, height, width)\n            \n            # Normalize and resize\n            volume = self.preprocess_volume(volume)\n            \n            return volume\n            \n        except Exception as e:\n            print(f\"Error processing series {series_path}: {e}\")\n            # Return zeros if processing fails\n            return np.zeros(self.target_size, dtype=np.float32)\n    \n    def preprocess_volume(self, volume: np.ndarray) -> np.ndarray:\n        \"\"\"Preprocess 3D volume: normalize, clip, resize\"\"\"\n        # Handle potential issues\n        if volume.size == 0:\n            return np.zeros(self.target_size, dtype=np.float32)\n        \n        # Clip extreme values (robust to outliers)\n        p1, p99 = np.percentile(volume, [1, 99])\n        volume = np.clip(volume, p1, p99)\n        \n        # Normalize to [0, 1]\n        volume_min, volume_max = volume.min(), volume.max()\n        if volume_max > volume_min:\n            volume = (volume - volume_min) / (volume_max - volume_min)\n        \n        # Resize to target size\n        if volume.shape != self.target_size:\n            zoom_factors = [\n                self.target_size[i] / volume.shape[i] for i in range(3)\n            ]\n            volume = ndimage.zoom(volume, zoom_factors, order=1)\n        \n        return volume.astype(np.float32)\n\nclass Simple3DCNN(nn.Module):\n    \"\"\"Lightweight 3D CNN for aneurysm detection\"\"\"\n    \n    def __init__(self, num_classes: int = len(LABEL_COLS)):\n        super(Simple3DCNN, self).__init__()\n        \n        # 3D Convolutional layers\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool3d(2)\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool3d(2)\n        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n        self.pool3 = nn.MaxPool3d(2)\n        self.conv4 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool3d(2)\n        \n        # Adaptive pooling to handle variable sizes\n        self.adaptive_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 2 * 2 * 2, 256)\n        self.dropout1 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 128)\n        self.dropout2 = nn.Dropout(0.3)\n        self.fc3 = nn.Linear(128, num_classes)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm3d(16)\n        self.bn2 = nn.BatchNorm3d(32)\n        self.bn3 = nn.BatchNorm3d(64)\n        self.bn4 = nn.BatchNorm3d(128)\n        \n    def forward(self, x):\n        # Input shape: (batch_size, 1, depth, height, width)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n        \n        # Adaptive pooling\n        x = self.adaptive_pool(x)\n        \n        # Flatten\n        x = x.view(x.size(0), -1)\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        \n        return torch.sigmoid(x)\n\nclass AneurysmDataset(Dataset):\n    \"\"\"Dataset for loading training data\"\"\"\n    \n    def __init__(self, data_df: pd.DataFrame, series_dir: str, processor: DICOMProcessor):\n        self.data_df = data_df\n        self.series_dir = series_dir\n        self.processor = processor\n        \n    def __len__(self):\n        return len(self.data_df)\n    \n    def __getitem__(self, idx):\n        row = self.data_df.iloc[idx]\n        series_id = row[ID_COL]\n        \n        # Load volume\n        series_path = os.path.join(self.series_dir, series_id)\n        volume = self.processor.load_dicom_series(series_path)\n        \n        # Get labels\n        labels = row[LABEL_COLS].values.astype(np.float32)\n        \n        # Convert to tensor and add channel dimension\n        volume_tensor = torch.from_numpy(volume).unsqueeze(0)  # Add channel dim\n        labels_tensor = torch.from_numpy(labels)\n        \n        return volume_tensor, labels_tensor\n\n# Global model and processor\nmodel = None\nprocessor = None\n\ndef initialize_model():\n    \"\"\"Initialize model and processor (called once)\"\"\"\n    global model, processor\n    \n    if model is not None:\n        return\n    \n    print(\"Initializing model...\")\n    processor = DICOMProcessor(TARGET_SIZE)\n    model = Simple3DCNN(num_classes=len(LABEL_COLS))\n    \n    # Load pre-trained weights if available\n    try:\n        if os.path.exists('/kaggle/input/model_weights.pth'):\n            model.load_state_dict(torch.load('/kaggle/input/model_weights.pth', map_location='cpu'))\n            print(\"Loaded pre-trained weights\")\n        else:\n            print(\"No pre-trained weights found, using random initialization\")\n    except Exception as e:\n        print(f\"Error loading weights: {e}\")\n    \n    model.to(DEVICE)\n    model.eval()\n    print(f\"Model initialized on {DEVICE}\")\n\ndef predict(series_path: str) -> pl.DataFrame:\n    \"\"\"Make prediction for a single series\"\"\"\n    \n    # Initialize model on first call\n    initialize_model()\n    \n    series_id = os.path.basename(series_path)\n    \n    try:\n        # Process the DICOM series\n        volume = processor.load_dicom_series(series_path)\n        \n        # Convert to tensor and add batch dimension\n        volume_tensor = torch.from_numpy(volume).unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)\n        volume_tensor = volume_tensor.to(DEVICE)\n        \n        # Make prediction\n        with torch.no_grad():\n            predictions = model(volume_tensor)\n            predictions = predictions.cpu().numpy().flatten()\n        \n        # Create result DataFrame\n        result_data = [[series_id] + predictions.tolist()]\n        result_df = pl.DataFrame(\n            data=result_data,\n            schema=[ID_COL] + LABEL_COLS,\n            orient='row'\n        )\n        \n        # Clean up memory\n        del volume_tensor\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    except Exception as e:\n        print(f\"Error predicting for series {series_id}: {e}\")\n        # Return baseline predictions (0.5 for all classes)\n        result_data = [[series_id] + [0.5] * len(LABEL_COLS)]\n        result_df = pl.DataFrame(\n            data=result_data,\n            schema=[ID_COL] + LABEL_COLS,\n            orient='row'\n        )\n    \n    # Mandatory cleanup\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    \n    return result_df.drop(ID_COL)\n\ndef train_model(train_df_path: str, series_dir: \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\", num_epochs: int = 50, batch_size: int = 32):\n    \"\"\"Training function (for reference - would be run separately)\"\"\"\n    \n    # Load training data\n    train_df = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv\")\n    \n    # Initialize components\n    processor = DICOMProcessor(TARGET_SIZE)\n    model = Simple3DCNN(num_classes=len(LABEL_COLS))\n    model.to(DEVICE)\n    \n    # Create dataset and dataloader\n    dataset = AneurysmDataset(train_df, series_dir, processor)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n    \n    # Loss and optimizer\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)\n    \n    # Training loop\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        num_batches = 0\n        \n        for batch_idx, (volumes, labels) in enumerate(dataloader):\n            volumes, labels = volumes.to(DEVICE), labels.to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(volumes)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            num_batches += 1\n            \n            if batch_idx % 10 == 0:\n                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.4f}')\n        \n        avg_loss = total_loss / num_batches\n        scheduler.step(avg_loss)\n        print(f'Epoch {epoch+1}/{num_epochs} completed, Average Loss: {avg_loss:.4f}')\n    \n    # Save model\n    torch.save(model.state_dict(), 'model_weights.pth')\n    print(\"Model saved to model_weights.pth\")\n\n# Competition server setup\ninference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway()\n    display(pl.read_parquet('/kaggle/working/submission.parquet'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:35:58.317252Z","iopub.execute_input":"2025-11-14T16:35:58.317565Z","iopub.status.idle":"2025-11-14T16:36:30.56301Z","shell.execute_reply.started":"2025-11-14T16:35:58.317543Z","shell.execute_reply":"2025-11-14T16:36:30.562208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
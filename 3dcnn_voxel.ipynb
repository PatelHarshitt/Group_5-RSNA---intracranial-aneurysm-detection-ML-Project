{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 99552,
          "databundleVersionId": 13851420,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "3dcnn voxel",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatelHarshitt/Group_5-RSNA---intracranial-aneurysm-detection-ML-Project/blob/main/3dcnn_voxel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "cg6mb-4HaBwv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "rsna_intracranial_aneurysm_detection_path = kagglehub.competition_download('rsna-intracranial-aneurysm-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "NInaQqKHaBwx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv')\n",
        "train_df.head()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:11:34.53433Z",
          "iopub.execute_input": "2025-11-14T16:11:34.535137Z",
          "iopub.status.idle": "2025-11-14T16:11:34.835505Z",
          "shell.execute_reply.started": "2025-11-14T16:11:34.535111Z",
          "shell.execute_reply": "2025-11-14T16:11:34.834668Z"
        },
        "id": "YAUmk-G0aBwx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "location_cols = [col for col in train_df.columns if col not in ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Aneurysm Present']]\n",
        "location_counts = train_df[location_cols].sum().sort_values(ascending=False)\n",
        "\n",
        "fig = px.bar(\n",
        "    location_counts,\n",
        "    orientation='v',\n",
        "    title=' Aneurysm Count by Location',\n",
        "    labels={'value': 'Count', 'index': 'Location'},\n",
        "    color=location_counts.values,\n",
        "\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:14:37.636476Z",
          "iopub.execute_input": "2025-11-14T16:14:37.636945Z",
          "iopub.status.idle": "2025-11-14T16:14:37.683333Z",
          "shell.execute_reply.started": "2025-11-14T16:14:37.63692Z",
          "shell.execute_reply": "2025-11-14T16:14:37.68271Z"
        },
        "id": "R_u2mlnmaBwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(\n",
        "    data=train_df,\n",
        "    x='PatientAge',\n",
        "    hue='Aneurysm Present',\n",
        "    bins=30,\n",
        "    kde=True,\n",
        "    palette={0: '#00BFC4', 1: '#C77CFF'}\n",
        ")\n",
        "plt.title(\"Age Distribution by Aneurysm Presence\", fontsize=14)\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:15:36.005969Z",
          "iopub.execute_input": "2025-11-14T16:15:36.006665Z",
          "iopub.status.idle": "2025-11-14T16:15:36.346948Z",
          "shell.execute_reply.started": "2025-11-14T16:15:36.006639Z",
          "shell.execute_reply": "2025-11-14T16:15:36.346283Z"
        },
        "id": "HydAGYP2aBwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(\n",
        "    train_df,\n",
        "    x='Aneurysm Present',\n",
        "    title='âš–ï¸ Class Imbalance: Any Aneurysm Present',\n",
        "    color='Aneurysm Present',\n",
        "    text_auto=True,\n",
        "    color_discrete_map={0: '#00BFC4', 1: '#C77CFF'},\n",
        "    template='plotly_dark'\n",
        ")\n",
        "fig.update_xaxes(type='category', tickvals=[0, 1], ticktext=[\"No Aneurysm\", \"Aneurysm\"])\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:16:34.180916Z",
          "iopub.execute_input": "2025-11-14T16:16:34.181233Z",
          "iopub.status.idle": "2025-11-14T16:16:34.278448Z",
          "shell.execute_reply.started": "2025-11-14T16:16:34.181213Z",
          "shell.execute_reply": "2025-11-14T16:16:34.277833Z"
        },
        "id": "5trVyT5eaBwz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple % table (can be styled in notebook output)\n",
        "gender_ct = pd.crosstab(train_df['PatientSex'], train_df['Aneurysm Present'], normalize='index') * 100\n",
        "gender_ct = gender_ct.rename(columns={0: 'No Aneurysm (%)', 1: 'Aneurysm (%)'})\n",
        "gender_ct.style.background_gradient(cmap='crest').format(\"{:.1f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:17:17.558325Z",
          "iopub.execute_input": "2025-11-14T16:17:17.558854Z",
          "iopub.status.idle": "2025-11-14T16:17:17.654169Z",
          "shell.execute_reply.started": "2025-11-14T16:17:17.558834Z",
          "shell.execute_reply": "2025-11-14T16:17:17.653576Z"
        },
        "id": "HN4zWR2jaBw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "localizers_df = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv')\n",
        "\n",
        "# Convert coordinate strings to dicts\n",
        "localizers_df['coords'] = localizers_df['coordinates'].apply(ast.literal_eval)\n",
        "localizers_df['x'] = localizers_df['coords'].apply(lambda d: d['x'])\n",
        "localizers_df['y'] = localizers_df['coords'].apply(lambda d: d['y'])\n",
        "\n",
        "localizers_df.drop(columns=['coordinates', 'coords'], inplace=True)\n",
        "localizers_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:18:37.347763Z",
          "iopub.execute_input": "2025-11-14T16:18:37.348616Z",
          "iopub.status.idle": "2025-11-14T16:18:37.409982Z",
          "shell.execute_reply.started": "2025-11-14T16:18:37.348591Z",
          "shell.execute_reply": "2025-11-14T16:18:37.409396Z"
        },
        "id": "pjsgmco3aBw1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.density_heatmap(\n",
        "    localizers_df,\n",
        "    x='x',\n",
        "    y='y',\n",
        "    nbinsx=50,\n",
        "    nbinsy=50,\n",
        "    title='ðŸ§  Heatmap of Aneurysm Locations in 2D Image Space',\n",
        "    color_continuous_scale='Turbo',\n",
        "    template='plotly_dark',\n",
        ")\n",
        "fig.update_yaxes(autorange=\"reversed\")\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:19:14.237784Z",
          "iopub.execute_input": "2025-11-14T16:19:14.238269Z",
          "iopub.status.idle": "2025-11-14T16:19:14.277393Z",
          "shell.execute_reply.started": "2025-11-14T16:19:14.238245Z",
          "shell.execute_reply": "2025-11-14T16:19:14.276761Z"
        },
        "id": "zbYMbVhtaBw2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(\n",
        "    localizers_df,\n",
        "    x='x',\n",
        "    y='y',\n",
        "    color='location',\n",
        "    title='ðŸ§  2D Scatter of Aneurysm Coordinates by Location',\n",
        "    template='plotly_dark',\n",
        "    color_discrete_sequence=px.colors.qualitative.Dark24\n",
        ")\n",
        "fig.update_yaxes(autorange=\"reversed\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:19:33.518548Z",
          "iopub.execute_input": "2025-11-14T16:19:33.518839Z",
          "iopub.status.idle": "2025-11-14T16:19:33.589132Z",
          "shell.execute_reply.started": "2025-11-14T16:19:33.51882Z",
          "shell.execute_reply": "2025-11-14T16:19:33.588403Z"
        },
        "id": "X1sx2PcJaBw2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = train_df\n",
        "# Identify location columns correctly\n",
        "location_cols = df.columns[4:-1]  # skip UID, Age, Sex, Modality, and skip final label\n",
        "location_df = df[location_cols].astype(int)  # just in case they're still object type\n",
        "\n",
        "# Co-occurrence matrix\n",
        "co_matrix = location_df.T.dot(location_df)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(co_matrix, cmap=\"magma\", annot=True, fmt=\".0f\", linewidths=0.5)\n",
        "plt.title(\"ðŸ§  Aneurysm Co-occurrence Matrix\", fontsize=16, color='white')\n",
        "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
        "plt.yticks(rotation=0, fontsize=9)\n",
        "plt.gca().set_facecolor('black')\n",
        "plt.gcf().set_facecolor('#111111')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:21:05.489195Z",
          "iopub.execute_input": "2025-11-14T16:21:05.489819Z",
          "iopub.status.idle": "2025-11-14T16:21:06.080563Z",
          "shell.execute_reply.started": "2025-11-14T16:21:05.489794Z",
          "shell.execute_reply": "2025-11-14T16:21:06.079748Z"
        },
        "id": "gXcD90qmaBw3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Location Count Distribution (number of 1s per row)\n",
        "location_counts = location_df.sum(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(location_counts, bins=range(1, location_counts.max()+2), kde=False, color=\"teal\")\n",
        "plt.title(\"Distribution of Aneurysm Locations per Patient\")\n",
        "plt.xlabel(\"Number of Locations with Aneurysm\")\n",
        "plt.ylabel(\"Number of Patients\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:22:03.219842Z",
          "iopub.execute_input": "2025-11-14T16:22:03.22059Z",
          "iopub.status.idle": "2025-11-14T16:22:03.413981Z",
          "shell.execute_reply.started": "2025-11-14T16:22:03.220564Z",
          "shell.execute_reply": "2025-11-14T16:22:03.413404Z"
        },
        "id": "F_CdfCntaBw3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is already loaded and preprocessed (i.e., binary columns are int)\n",
        "\n",
        "# Filter only rows where aneurysm is present\n",
        "df_pos = df[df[\"Aneurysm Present\"] == 1]\n",
        "\n",
        "# List of all aneurysm location columns\n",
        "location_cols = df_pos.columns[4:-1]  # From 'Left Infraclinoid...' to 'Other Posterior Circulation'\n",
        "\n",
        "# Group by PatientSex and sum each location\n",
        "sex_location = df_pos.groupby(\"PatientSex\")[location_cols].sum().T\n",
        "\n",
        "# Reset index for plotting\n",
        "sex_location = sex_location.reset_index().melt(id_vars=\"index\", var_name=\"Sex\", value_name=\"Count\")\n",
        "sex_location = sex_location.rename(columns={\"index\": \"Location\"})\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(16, 6))\n",
        "sns.barplot(data=sex_location, x=\"Location\", y=\"Count\", hue=\"Sex\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.title(\"ðŸ§¬ Aneurysm Location Frequency by Sex\")\n",
        "plt.ylabel(\"Aneurysm Count\")\n",
        "plt.xlabel(\"Location\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:23:04.275654Z",
          "iopub.execute_input": "2025-11-14T16:23:04.27641Z",
          "iopub.status.idle": "2025-11-14T16:23:04.612153Z",
          "shell.execute_reply.started": "2025-11-14T16:23:04.276377Z",
          "shell.execute_reply": "2025-11-14T16:23:04.611535Z"
        },
        "id": "x4Hu5ggsaBw3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows with aneurysm present\n",
        "df_pos = df[df[\"Aneurysm Present\"] == 1].copy()\n",
        "\n",
        "# Initialize a dictionary to store counts\n",
        "modality_counts = {}\n",
        "\n",
        "for loc in location_cols:\n",
        "    subset = df_pos[df_pos[loc] == 1]\n",
        "    modality_distribution = subset[\"Modality\"].value_counts()\n",
        "    modality_counts[loc] = modality_distribution\n",
        "\n",
        "# Convert to DataFrame and fill missing values with 0\n",
        "modality_df = pd.DataFrame(modality_counts).T.fillna(0).astype(int)\n",
        "modality_df = modality_df[[\"CTA\", \"MRA\"]] if \"CTA\" in modality_df.columns and \"MRA\" in modality_df.columns else modality_df\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(modality_df.T, annot=True, cmap=\"crest\", fmt=\"d\")\n",
        "plt.title(\"ðŸ§  Modality Preference per Aneurysm Location\")\n",
        "plt.xlabel(\"Location\")\n",
        "plt.ylabel(\"Modality\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:24:21.601963Z",
          "iopub.execute_input": "2025-11-14T16:24:21.602527Z",
          "iopub.status.idle": "2025-11-14T16:24:22.086831Z",
          "shell.execute_reply.started": "2025-11-14T16:24:21.6025Z",
          "shell.execute_reply": "2025-11-14T16:24:22.086097Z"
        },
        "id": "8U5SxJPUaBw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "modality_df_melted = modality_df.reset_index().melt(id_vars=\"index\", value_name=\"Count\", var_name=\"Modality\")\n",
        "modality_df_melted.rename(columns={\"index\": \"Location\"}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(data=modality_df_melted, x=\"Location\", y=\"Count\", hue=\"Modality\", palette=\"crest\")\n",
        "plt.title(\"ðŸ§  Modality Usage per Aneurysm Location\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.xlabel(\"Location\")\n",
        "plt.ylabel(\"Patient Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:24:34.016893Z",
          "iopub.execute_input": "2025-11-14T16:24:34.017604Z",
          "iopub.status.idle": "2025-11-14T16:24:34.335534Z",
          "shell.execute_reply.started": "2025-11-14T16:24:34.017581Z",
          "shell.execute_reply": "2025-11-14T16:24:34.33478Z"
        },
        "id": "9TLCUnkWaBw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "train_localizations = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv\")\n",
        "# Parse coordinates\n",
        "train_localizations[\"coord_dict\"] = train_localizations[\"coordinates\"].apply(ast.literal_eval)\n",
        "train_localizations[\"x\"] = train_localizations[\"coord_dict\"].apply(lambda d: d[\"x\"])\n",
        "train_localizations[\"y\"] = train_localizations[\"coord_dict\"].apply(lambda d: d[\"y\"])\n",
        "\n",
        "# Top 4-5 most frequent locations\n",
        "top_locations = train_localizations[\"location\"].value_counts().head(5).index\n",
        "\n",
        "# Plot heatmap per location\n",
        "for loc in top_locations:\n",
        "    subset = train_localizations[train_localizations[\"location\"] == loc]\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.kdeplot(data=subset, x=\"x\", y=\"y\", fill=True, cmap=\"crest\")\n",
        "    plt.title(f\"ðŸ§­ Spatial Heatmap for {loc}\")\n",
        "    plt.xlabel(\"X Coordinate\")\n",
        "    plt.ylabel(\"Y Coordinate\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:25:34.690841Z",
          "iopub.execute_input": "2025-11-14T16:25:34.691123Z",
          "iopub.status.idle": "2025-11-14T16:25:36.724693Z",
          "shell.execute_reply.started": "2025-11-14T16:25:34.691103Z",
          "shell.execute_reply": "2025-11-14T16:25:36.723955Z"
        },
        "id": "2dypdZf5aBw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv\")\n",
        "# Frequency from train.csv\n",
        "label_freq = train[location_cols].sum().sort_values(ascending=False).rename(\"train.csv\")\n",
        "\n",
        "# Frequency from localizations.csv\n",
        "localizer_freq = train_localizations[\"location\"].value_counts().rename(\"train_localizations.csv\")\n",
        "\n",
        "# Combine\n",
        "freq_comparison = pd.concat([label_freq, localizer_freq], axis=1).fillna(0).astype(int)\n",
        "\n",
        "# Bar plot\n",
        "freq_comparison.plot(kind=\"bar\", figsize=(14, 6), color=['#00BFC4',  '#C77CFF'])\n",
        "plt.title(\"ðŸ”„ Frequency Comparison of Aneurysm Locations\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:25:42.279896Z",
          "iopub.execute_input": "2025-11-14T16:25:42.28019Z",
          "iopub.status.idle": "2025-11-14T16:25:42.623554Z",
          "shell.execute_reply.started": "2025-11-14T16:25:42.280167Z",
          "shell.execute_reply": "2025-11-14T16:25:42.62286Z"
        },
        "id": "tSW272VKaBw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "series_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/series'\n",
        "series_folders = [f for f in os.listdir(series_dir) if os.path.isdir(os.path.join(series_dir, f))]\n",
        "\n",
        "series_counts = []\n",
        "for folder in series_folders:\n",
        "    dcm_files = os.listdir(os.path.join(series_dir, folder))\n",
        "    series_counts.append({'SeriesInstanceUID': folder, 'NumSlices': len(dcm_files)})\n",
        "\n",
        "df_series = pd.DataFrame(series_counts)\n",
        "df_series.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:25:56.372598Z",
          "iopub.execute_input": "2025-11-14T16:25:56.373336Z",
          "iopub.status.idle": "2025-11-14T16:32:02.433972Z",
          "shell.execute_reply.started": "2025-11-14T16:25:56.373314Z",
          "shell.execute_reply": "2025-11-14T16:32:02.433173Z"
        },
        "id": "xNGuNi5HaBw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom\n",
        "\n",
        "sample_path = os.path.join(series_dir, series_folders[0])\n",
        "sample_file = os.listdir(sample_path)[0]\n",
        "dcm = pydicom.dcmread(os.path.join(sample_path, sample_file))\n",
        "\n",
        "print(f\"Orientation: {dcm.ImageOrientationPatient}\")\n",
        "print(f\"Voxel spacing: {dcm.PixelSpacing}\")\n",
        "print(f\"Slice Thickness: {dcm.SliceThickness}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:32:15.202881Z",
          "iopub.execute_input": "2025-11-14T16:32:15.203526Z",
          "iopub.status.idle": "2025-11-14T16:32:15.697172Z",
          "shell.execute_reply.started": "2025-11-14T16:32:15.203498Z",
          "shell.execute_reply": "2025-11-14T16:32:15.696406Z"
        },
        "id": "JpsUxY0haBw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.widgets as widgets\n",
        "import numpy as np\n",
        "\n",
        "def load_series(series_path):\n",
        "    files = sorted(os.listdir(series_path), key=lambda x: pydicom.dcmread(os.path.join(series_path, x)).InstanceNumber)\n",
        "    images = [pydicom.dcmread(os.path.join(series_path, f)).pixel_array for f in files]\n",
        "    return np.stack(images)\n",
        "\n",
        "volume = load_series(os.path.join(series_dir, series_folders[0]))\n",
        "\n",
        "# Scrollable plot\n",
        "from ipywidgets import interact\n",
        "@interact(slice=(0, volume.shape[0]-1))\n",
        "def show_slice(slice=0):\n",
        "    plt.imshow(volume[slice], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:32:20.705712Z",
          "iopub.execute_input": "2025-11-14T16:32:20.706301Z",
          "iopub.status.idle": "2025-11-14T16:32:23.960058Z",
          "shell.execute_reply.started": "2025-11-14T16:32:20.706279Z",
          "shell.execute_reply": "2025-11-14T16:32:23.959302Z"
        },
        "id": "XL83f5ftaBw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "\n",
        "# Count slices and shape per series\n",
        "dicom_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/series'\n",
        "series_stats = []\n",
        "\n",
        "for series_id in os.listdir(dicom_dir)[:50]:  # limit for speed\n",
        "    series_path = os.path.join(dicom_dir, series_id)\n",
        "    files = os.listdir(series_path)\n",
        "    num_slices = len(files)\n",
        "    sample_dcm = pydicom.dcmread(os.path.join(series_path, files[0]))\n",
        "    shape = (sample_dcm.Rows, sample_dcm.Columns)\n",
        "    series_stats.append({\"SeriesInstanceUID\": series_id, \"Slices\": num_slices, \"Shape\": shape})\n",
        "\n",
        "pd.DataFrame(series_stats).value_counts(\"Shape\").plot(kind=\"barh\", title=\"ðŸ–¼ Common Image Resolutions\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:32:50.300331Z",
          "iopub.execute_input": "2025-11-14T16:32:50.300939Z",
          "iopub.status.idle": "2025-11-14T16:32:52.509123Z",
          "shell.execute_reply.started": "2025-11-14T16:32:50.300913Z",
          "shell.execute_reply": "2025-11-14T16:32:52.50841Z"
        },
        "id": "SBspu0s3aBw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "voxel_data = []\n",
        "\n",
        "for series_id in os.listdir(dicom_dir)[:50]:\n",
        "    slices = []\n",
        "    for f in sorted(os.listdir(os.path.join(dicom_dir, series_id))):\n",
        "        path = os.path.join(dicom_dir, series_id, f)\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        slices.append(dcm)\n",
        "\n",
        "    try:\n",
        "        spacing = slices[0].PixelSpacing\n",
        "        thickness = float(slices[0].SliceThickness)\n",
        "        voxel_data.append({\n",
        "            \"SeriesInstanceUID\": series_id,\n",
        "            \"PixelSpacingX\": spacing[0],\n",
        "            \"PixelSpacingY\": spacing[1],\n",
        "            \"SliceThickness\": thickness,\n",
        "            \"NumSlices\": len(slices)\n",
        "        })\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "voxel_df = pd.DataFrame(voxel_data)\n",
        "sns.histplot(voxel_df[\"SliceThickness\"], bins=20)\n",
        "plt.title(\"ðŸ“ Slice Thickness Distribution\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:32:54.925679Z",
          "iopub.execute_input": "2025-11-14T16:32:54.925954Z",
          "iopub.status.idle": "2025-11-14T16:35:00.319296Z",
          "shell.execute_reply.started": "2025-11-14T16:32:54.925933Z",
          "shell.execute_reply": "2025-11-14T16:35:00.318682Z"
        },
        "id": "ToIEZcgsaBw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import gc\n",
        "from collections import defaultdict\n",
        "from typing import Tuple, List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import pydicom\n",
        "from scipy import ndimage\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import kaggle_evaluation.rsna_inference_server\n",
        "\n",
        "# Competition constants\n",
        "ID_COL = 'SeriesInstanceUID'\n",
        "LABEL_COLS = [\n",
        "    'Left Infraclinoid Internal Carotid Artery',\n",
        "    'Right Infraclinoid Internal Carotid Artery',\n",
        "    'Left Supraclinoid Internal Carotid Artery',\n",
        "    'Right Supraclinoid Internal Carotid Artery',\n",
        "    'Left Middle Cerebral Artery',\n",
        "    'Right Middle Cerebral Artery',\n",
        "    'Anterior Communicating Artery',\n",
        "    'Left Anterior Cerebral Artery',\n",
        "    'Right Anterior Cerebral Artery',\n",
        "    'Left Posterior Communicating Artery',\n",
        "    'Right Posterior Communicating Artery',\n",
        "    'Basilar Tip',\n",
        "    'Other Posterior Circulation',\n",
        "    'Aneurysm Present',\n",
        "]\n",
        "\n",
        "DICOM_TAG_ALLOWLIST = [\n",
        "    'BitsAllocated', 'BitsStored', 'Columns', 'FrameOfReferenceUID', 'HighBit',\n",
        "    'ImageOrientationPatient', 'ImagePositionPatient', 'InstanceNumber', 'Modality',\n",
        "    'PatientID', 'PhotometricInterpretation', 'PixelRepresentation', 'PixelSpacing',\n",
        "    'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope', 'RescaleType', 'Rows',\n",
        "    'SOPClassUID', 'SOPInstanceUID', 'SamplesPerPixel', 'SliceThickness',\n",
        "    'SpacingBetweenSlices', 'StudyInstanceUID', 'TransferSyntaxUID',\n",
        "]\n",
        "\n",
        "# Model configuration\n",
        "TARGET_SIZE = (64, 64, 64)  # Reduced size for memory efficiency\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class DICOMProcessor:\n",
        "    \"\"\"Process DICOM series into normalized 3D volumes\"\"\"\n",
        "\n",
        "    def __init__(self, target_size: Tuple[int, int, int] = TARGET_SIZE):\n",
        "        self.target_size = target_size\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_dicom_series(self, series_path: str) -> np.ndarray:\n",
        "        \"\"\"Load and process a DICOM series into a 3D volume\"\"\"\n",
        "        try:\n",
        "            # Get all DICOM files\n",
        "            dicom_files = []\n",
        "            for root, _, files in os.walk(series_path):\n",
        "                for file in files:\n",
        "                    if file.endswith('.dcm'):\n",
        "                        dicom_files.append(os.path.join(root, file))\n",
        "\n",
        "            if not dicom_files:\n",
        "                raise ValueError(f\"No DICOM files found in {series_path}\")\n",
        "\n",
        "            # Load DICOMs and sort by instance number\n",
        "            dicoms = []\n",
        "            for filepath in dicom_files:\n",
        "                try:\n",
        "                    ds = pydicom.dcmread(filepath, force=True)\n",
        "                    if hasattr(ds, 'PixelData'):\n",
        "                        dicoms.append((ds, filepath))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {filepath}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not dicoms:\n",
        "                raise ValueError(f\"No valid DICOM files with pixel data in {series_path}\")\n",
        "\n",
        "            # Sort by instance number\n",
        "            dicoms.sort(key=lambda x: getattr(x[0], 'InstanceNumber', 0))\n",
        "\n",
        "            # Extract volume\n",
        "            volume_slices = []\n",
        "            for ds, _ in dicoms:\n",
        "                try:\n",
        "                    # Get pixel array\n",
        "                    pixel_array = ds.pixel_array.astype(np.float32)\n",
        "\n",
        "                    # Apply rescale if available\n",
        "                    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
        "                        slope = float(ds.RescaleSlope)\n",
        "                        intercept = float(ds.RescaleIntercept)\n",
        "                        pixel_array = pixel_array * slope + intercept\n",
        "\n",
        "                    volume_slices.append(pixel_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing slice: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not volume_slices:\n",
        "                raise ValueError(\"No valid slices extracted\")\n",
        "\n",
        "            # Stack into 3D volume\n",
        "            volume = np.stack(volume_slices, axis=0)  # Shape: (depth, height, width)\n",
        "\n",
        "            # Normalize and resize\n",
        "            volume = self.preprocess_volume(volume)\n",
        "\n",
        "            return volume\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing series {series_path}: {e}\")\n",
        "            # Return zeros if processing fails\n",
        "            return np.zeros(self.target_size, dtype=np.float32)\n",
        "\n",
        "    def preprocess_volume(self, volume: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Preprocess 3D volume: normalize, clip, resize\"\"\"\n",
        "        # Handle potential issues\n",
        "        if volume.size == 0:\n",
        "            return np.zeros(self.target_size, dtype=np.float32)\n",
        "\n",
        "        # Clip extreme values (robust to outliers)\n",
        "        p1, p99 = np.percentile(volume, [1, 99])\n",
        "        volume = np.clip(volume, p1, p99)\n",
        "\n",
        "        # Normalize to [0, 1]\n",
        "        volume_min, volume_max = volume.min(), volume.max()\n",
        "        if volume_max > volume_min:\n",
        "            volume = (volume - volume_min) / (volume_max - volume_min)\n",
        "\n",
        "        # Resize to target size\n",
        "        if volume.shape != self.target_size:\n",
        "            zoom_factors = [\n",
        "                self.target_size[i] / volume.shape[i] for i in range(3)\n",
        "            ]\n",
        "            volume = ndimage.zoom(volume, zoom_factors, order=1)\n",
        "\n",
        "        return volume.astype(np.float32)\n",
        "\n",
        "class Simple3DCNN(nn.Module):\n",
        "    \"\"\"Lightweight 3D CNN for aneurysm detection\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes: int = len(LABEL_COLS)):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "\n",
        "        # 3D Convolutional layers\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool3d(2)\n",
        "        self.conv4 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool4 = nn.MaxPool3d(2)\n",
        "\n",
        "        # Adaptive pooling to handle variable sizes\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2 * 2, 256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        # Batch normalization\n",
        "        self.bn1 = nn.BatchNorm3d(16)\n",
        "        self.bn2 = nn.BatchNorm3d(32)\n",
        "        self.bn3 = nn.BatchNorm3d(64)\n",
        "        self.bn4 = nn.BatchNorm3d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape: (batch_size, 1, depth, height, width)\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        # Adaptive pooling\n",
        "        x = self.adaptive_pool(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "class AneurysmDataset(Dataset):\n",
        "    \"\"\"Dataset for loading training data\"\"\"\n",
        "\n",
        "    def __init__(self, data_df: pd.DataFrame, series_dir: str, processor: DICOMProcessor):\n",
        "        self.data_df = data_df\n",
        "        self.series_dir = series_dir\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data_df.iloc[idx]\n",
        "        series_id = row[ID_COL]\n",
        "\n",
        "        # Load volume\n",
        "        series_path = os.path.join(self.series_dir, series_id)\n",
        "        volume = self.processor.load_dicom_series(series_path)\n",
        "\n",
        "        # Get labels\n",
        "        labels = row[LABEL_COLS].values.astype(np.float32)\n",
        "\n",
        "        # Convert to tensor and add channel dimension\n",
        "        volume_tensor = torch.from_numpy(volume).unsqueeze(0)  # Add channel dim\n",
        "        labels_tensor = torch.from_numpy(labels)\n",
        "\n",
        "        return volume_tensor, labels_tensor\n",
        "\n",
        "# Global model and processor\n",
        "model = None\n",
        "processor = None\n",
        "\n",
        "def initialize_model():\n",
        "    \"\"\"Initialize model and processor (called once)\"\"\"\n",
        "    global model, processor\n",
        "\n",
        "    if model is not None:\n",
        "        return\n",
        "\n",
        "    print(\"Initializing model...\")\n",
        "    processor = DICOMProcessor(TARGET_SIZE)\n",
        "    model = Simple3DCNN(num_classes=len(LABEL_COLS))\n",
        "\n",
        "    # Load pre-trained weights if available\n",
        "    try:\n",
        "        if os.path.exists('/kaggle/input/model_weights.pth'):\n",
        "            model.load_state_dict(torch.load('/kaggle/input/model_weights.pth', map_location='cpu'))\n",
        "            print(\"Loaded pre-trained weights\")\n",
        "        else:\n",
        "            print(\"No pre-trained weights found, using random initialization\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading weights: {e}\")\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    print(f\"Model initialized on {DEVICE}\")\n",
        "\n",
        "def predict(series_path: str) -> pl.DataFrame:\n",
        "    \"\"\"Make prediction for a single series\"\"\"\n",
        "\n",
        "    # Initialize model on first call\n",
        "    initialize_model()\n",
        "\n",
        "    series_id = os.path.basename(series_path)\n",
        "\n",
        "    try:\n",
        "        # Process the DICOM series\n",
        "        volume = processor.load_dicom_series(series_path)\n",
        "\n",
        "        # Convert to tensor and add batch dimension\n",
        "        volume_tensor = torch.from_numpy(volume).unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)\n",
        "        volume_tensor = volume_tensor.to(DEVICE)\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            predictions = model(volume_tensor)\n",
        "            predictions = predictions.cpu().numpy().flatten()\n",
        "\n",
        "        # Create result DataFrame\n",
        "        result_data = [[series_id] + predictions.tolist()]\n",
        "        result_df = pl.DataFrame(\n",
        "            data=result_data,\n",
        "            schema=[ID_COL] + LABEL_COLS,\n",
        "            orient='row'\n",
        "        )\n",
        "\n",
        "        # Clean up memory\n",
        "        del volume_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting for series {series_id}: {e}\")\n",
        "        # Return baseline predictions (0.5 for all classes)\n",
        "        result_data = [[series_id] + [0.5] * len(LABEL_COLS)]\n",
        "        result_df = pl.DataFrame(\n",
        "            data=result_data,\n",
        "            schema=[ID_COL] + LABEL_COLS,\n",
        "            orient='row'\n",
        "        )\n",
        "\n",
        "    # Mandatory cleanup\n",
        "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
        "\n",
        "    return result_df.drop(ID_COL)\n",
        "\n",
        "def train_model(train_df_path: str, series_dir: \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\", num_epochs: int = 50, batch_size: int = 32):\n",
        "    \"\"\"Training function (for reference - would be run separately)\"\"\"\n",
        "\n",
        "    # Load training data\n",
        "    train_df = pd.read_csv(\"/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv\")\n",
        "\n",
        "    # Initialize components\n",
        "    processor = DICOMProcessor(TARGET_SIZE)\n",
        "    model = Simple3DCNN(num_classes=len(LABEL_COLS))\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = AneurysmDataset(train_df, series_dir, processor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_idx, (volumes, labels) in enumerate(dataloader):\n",
        "            volumes, labels = volumes.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(volumes)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        scheduler.step(avg_loss)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} completed, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'model_weights.pth')\n",
        "    print(\"Model saved to model_weights.pth\")\n",
        "\n",
        "# Competition server setup\n",
        "inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway()\n",
        "    display(pl.read_parquet('/kaggle/working/submission.parquet'))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T16:35:58.317252Z",
          "iopub.execute_input": "2025-11-14T16:35:58.317565Z",
          "iopub.status.idle": "2025-11-14T16:36:30.56301Z",
          "shell.execute_reply.started": "2025-11-14T16:35:58.317543Z",
          "shell.execute_reply": "2025-11-14T16:36:30.562208Z"
        },
        "id": "24e6ooECaBw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NF_0X7KhaBw7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}